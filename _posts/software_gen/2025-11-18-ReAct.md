---
layout: post
title: "ReAct"
categories: software generation
---
# Introduction
In the previous [post](https://harc007.github.io/swe_assistant/2025/03/31/Langgraph.html), we built a small langgraph agent with 2 nodes. One node to check if task is a python coding task. The other node that actually generates the code. While both the nodes invoked the openAI gpt-3.5-turbo LLM, we will move to gemini-2.5-flash LLM for a change. But the bigger change today is that we will look at a framework called ReAct which stands for Reasoning & Acting. The idea of making this a separate post is to understand how to change the code to invoke a ReAct agent instead of a LLM directly.

# What is ReAct
We can think of ReAct agent as a wrapper around the LLM of your choice. They are designed to simulate reasoning and decision-making by mimicking how humans solve problems. ReAct agents makes the underlying LLMs iterative analyze questions, take actions and refine the outputs.
My favorite example of why ReAct works is a snapshot below from the paper ReAct: Synergizing Reasoning and Acting in Language Models. Click [here](https://arxiv.org/pdf/2210.03629) for the paper.
![alt text](/swe_assistant/docs/assets/react_20251118.jpg "ReAct")

# Code change
The code change is minimal from an invoking perspective. We just need to wrap a LLM of choice behind a ReAct package provided within the langchain library. There are some code changes in terms of how we manage what we return from an Langgraph agent perspective. Take a close look at the code below.

Below is to load the API keys
```
from dotenv import load_dotenv
load_dotenv()
```

The change below is defining the response format so as to get ReAct agent to always return response in a single format outside of just prompting for a standard response which is not full-proof. 
```
from typing import Annotated
from typing_extensions import TypedDict
from langgraph.graph import StateGraph, START, END
from langgraph.graph.message import add_messages

class State(TypedDict):
    messages: Annotated[list, add_messages]
    is_code_task: bool

graph_builder = StateGraph(State)

from pydantic import BaseModel, Field

class codebotResponse(BaseModel):
    question: str = Field(description="content part of the message which is question asked by user.")
    message: str = Field(description="Answer provided by codebot.")
```

In the below code we just add the wrapper to the LLM and invoke the ReAct agent wrapper.
```
from langchain_google_genai import ChatGoogleGenerativeAI
from typing import Literal
from langchain.agents import create_agent

llm = ChatGoogleGenerativeAI(
    model="gemini-2.5-flash",
    temperature=0,
    max_tokens=None,
    timeout=None,
    max_retries=2,
)
tools = []  # no tools / no external access
agent = create_agent(llm, tools, 
                     system_prompt="You are a helpful coding assistant. Write python code based on the user's request.", 
                     response_format=codebotResponse)

def codebot(state: State):
    print("state messages in codebot:", state["messages"][0].content)
    response = agent.invoke({"messages":[{"role":"user", "content":state["messages"][0].content}]})
    print("response from codebot:", response)
    return response
    # return {"messages": [response], "is_code_task":True}

def check_if_code_task(state: State):
    code_task_prompt = f"""Check if the user is asking you to write python code for 
                                     a specific problem within ``? `{state["messages"]}`
                            Return your answer as END if it is not a coding task. Return CODEBOT if it is a coding task. 
                            Remember that answer should only be 1 word."""
    print("code_task_prompt:", code_task_prompt)
    response = llm.invoke(code_task_prompt)
    print("response from check_if_code_task:", response.content)
    if response.content == "END":
        print("Assistant: This is not a python code generation request")
        return {"messages": [response], "is_code_task":False}
    return {"messages": [response], "is_code_task":True}

def should_continue(state:State)->Literal["codebot", END]:
    if state["is_code_task"]:
        return "codebot"
    return END

graph_builder.add_node("check_if_code_task", check_if_code_task)
graph_builder.add_node("codebot", codebot)
```

No changes to code below compared to the previous blog. Here, we are just creating the nodes and edges and executing the agent with user input.
```
graph_builder.add_edge(START, "check_if_code_task")
graph_builder.add_conditional_edges("check_if_code_task", should_continue)
graph_builder.add_edge("codebot", END)

graph = graph_builder.compile()

def stream_graph_updates(user_input: str):
    print("user input:", user_input)
    for event in graph.stream({
        "messages": [{
            "role": "user", 
            "content": user_input
        }], 
        "is_code_task": False
    }):
        print("event values", event.values())
        for value in event.values():
            print("Assistant:", value["messages"][-1].content)

while True:
    try:
        user_input = input("User: ")
        if user_input.lower() in ["quit", "exit", "q"]:
            print("Goodbye!")
            break
        stream_graph_updates(user_input)
    except Exception as e:
        raise e
```

# What is missing?
We notice that we have created a variable called tools and assigned it as an empty list. One of ReAct frameworks biggest strengths apart from simulating reasoning is that it has the great ability to use tools. But we have not provided any tools to this ReAct agent. What are tools and how does it help? We will look at that in the next post while continuing with the same example. Until then, look out the window and enjoy the weather!